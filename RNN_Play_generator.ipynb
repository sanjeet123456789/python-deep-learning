{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Play generator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhXowRRBik9RdqIX3eRCpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeet123456789/python-deep-learning/blob/master/RNN_Play_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nRReDJ_cyOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict the next word \n",
        "%tensorflow_version 2.x\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyZN_i2ldLXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset\n",
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I1KVTSZHi_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# path_to_file=list(files.upload().keys())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp4709tfH61L",
        "colab_type": "code",
        "outputId": "197a0abf-a0de-430b-b21a-313559ed2a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reading and decode the file\n",
        "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OuR3MD0IZCb",
        "colab_type": "code",
        "outputId": "b520ec4b-ce5e-48e8-ea77-a97d05b6bcba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhkVvo8gIdBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=sorted(set(text))\n",
        "#creating a mapping from unique characters to indices\n",
        "char2idx={u:i for i,u in enumerate(vocab)}\n",
        "idx2char=np.array(vocab)\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int=text_to_int(text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udOPwEFQJgPv",
        "colab_type": "code",
        "outputId": "89eba194-b334-4998-86bb-78423d057bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#looking at how of our text is encoded\n",
        "print(\"Text\",text[:13])\n",
        "print(\"Encoded:\",text_to_int(text[:13]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text First Citizen\n",
            "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYF9iTeNJxbo",
        "colab_type": "code",
        "outputId": "353508c1-77f0-44ba-de26-b165c90a9a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# creating function that convert numeric data to text\n",
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints=ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "    return ''.join(idx2char[ints])\n",
        "  \n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TfH7sQj2NiAc",
        "colab": {}
      },
      "source": [
        "#Training example\n",
        "seq_length=100 #length of sequence for a training example\n",
        "examples_per_epoch=len(text)//(seq_length+1)\n",
        "#input :hell|output:ello\n",
        "#create training examples/targets\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HIo1-ac0Nhfq",
        "colab": {}
      },
      "source": [
        "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjjcJ0kORXil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def split_input_target(chunk): # for the example hello\n",
        "  input_text=chunk[:-1] #hell\n",
        "  target_text=chunk[1:] #ello\n",
        "  return input_text, target_text #hell,ello\n",
        "dataset=sequences.map(split_input_target) #use map to apply the above function to every entry"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTIYQiF8N7jW",
        "colab_type": "code",
        "outputId": "fed2dcf2-ccd7-4e69-8a31-091547eb65b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"/n/nExample\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"/nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/n/nExample\n",
            "\n",
            "INPUT\n",
            "None\n",
            "/nOUTPUT\n",
            "None\n",
            "/n/nExample\n",
            "\n",
            "INPUT\n",
            "None\n",
            "/nOUTPUT\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yQxwy6DRukT",
        "colab_type": "code",
        "outputId": "57801b96-73cc-49fa-8e63-617c7f9570bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Training batches\n",
        "BATCH_SIZE=64\n",
        "VOCAB_SIZE=len(vocab)\n",
        "EMBEDDING_DIM=256\n",
        "RUN_UNITS=1024\n",
        "BUFFER_SIZE=1000\n",
        "#bufer size is to shuffle the dataset\n",
        "#so it doen't attempt to shuffle the entire sequence in memory .Instead\n",
        "#It maintained a buffer in which it shuffle elements\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IY9-_-tSemM",
        "colab_type": "code",
        "outputId": "6657e436-b14d-4e76-8023-066cd8be0735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#building a model\n",
        "\n",
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "  model=tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size,embedding_dim,\n",
        "                batch_input_shape=[batch_size,None]),\n",
        "        tf.keras.layers.LSTM(rnn_units,return_sequences=True,\n",
        "                             stateful=True,\n",
        "                             recurrent_initializer='glorot_uniform'\n",
        "                             ),\n",
        "          tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RUN_UNITS,BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaoOidFxU1Xy",
        "colab_type": "code",
        "outputId": "2e16f1b8-f9a0-46d0-e10c-712e11afeb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#creating loss function\n",
        "for input_example_batch,target_example_batch in data.take(1):\n",
        "  example_batch_predictions=model(input_example_batch)\n",
        "  print(example_batch_predictions.shape,\"#(batch_size,sequence_length,vocab_size)\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) #(batch_size,sequence_length,vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXkRDQoaWl1a",
        "colab_type": "code",
        "outputId": "5fde14a9-ecdd-4fdd-92c6-9160de10ecb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#see that the prediction is an array of 64 arrays one for each entry \n",
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 3.51623166e-03 -3.79694253e-03  2.13346956e-03 ... -4.05247835e-03\n",
            "    1.14340289e-03  8.70837481e-04]\n",
            "  [ 5.62787522e-03 -1.27550494e-03 -1.78282405e-03 ... -6.73815515e-03\n",
            "    1.10111060e-03  1.35404989e-05]\n",
            "  [ 1.18598389e-03 -2.62085162e-03  6.25679316e-03 ... -7.42010027e-03\n",
            "    2.61082174e-03 -9.49953101e-05]\n",
            "  ...\n",
            "  [-2.96839251e-04 -1.57493260e-02  5.64386649e-03 ... -6.07863301e-03\n",
            "   -2.60122633e-03 -9.38369893e-03]\n",
            "  [-1.46408670e-03 -1.32319937e-02  3.61787830e-03 ... -4.23203269e-03\n",
            "    1.93960033e-03 -5.36816800e-03]\n",
            "  [-3.29275429e-03 -1.24994675e-02  5.30999573e-03 ... -5.46788424e-03\n",
            "    2.68611964e-03 -9.61688720e-03]]\n",
            "\n",
            " [[ 3.51623166e-03 -3.79694253e-03  2.13346956e-03 ... -4.05247835e-03\n",
            "    1.14340289e-03  8.70837481e-04]\n",
            "  [ 2.31033540e-03  2.52306182e-03  5.83854131e-03 ...  5.19084511e-04\n",
            "   -1.30322413e-03 -5.11627179e-03]\n",
            "  [-8.56111990e-04 -2.71654525e-03  3.04728746e-06 ... -1.30363891e-03\n",
            "   -1.38279330e-03 -1.88365555e-03]\n",
            "  ...\n",
            "  [ 1.34319859e-03  1.92627171e-03 -4.33663139e-03 ...  1.70367025e-03\n",
            "    6.82213483e-03 -9.91954934e-03]\n",
            "  [-4.07704525e-03  2.73853308e-04 -5.69390692e-03 ...  3.96249862e-03\n",
            "    8.62609968e-03 -7.41907209e-03]\n",
            "  [-1.68496848e-03 -3.66711919e-03  2.12487997e-04 ...  3.23640462e-03\n",
            "    6.60546310e-03 -1.21270986e-02]]\n",
            "\n",
            " [[-5.27581433e-05  5.42132277e-03  5.71648311e-03 ...  2.97041563e-03\n",
            "   -1.60778605e-03 -6.27145497e-03]\n",
            "  [-4.17590141e-04  2.36998824e-03  3.78525769e-03 ...  8.16520071e-04\n",
            "   -4.11243783e-03 -1.21432422e-02]\n",
            "  [ 1.76606630e-03  1.24990614e-03 -3.53747467e-03 ...  3.71730374e-03\n",
            "    5.00356313e-03 -1.21535026e-02]\n",
            "  ...\n",
            "  [ 1.71611889e-03 -1.22298021e-03 -1.04149273e-02 ... -8.88353214e-04\n",
            "    4.91508888e-03 -1.03069404e-02]\n",
            "  [ 5.49444743e-03  5.01591712e-05 -1.04879793e-02 ... -5.65690314e-03\n",
            "    3.97731317e-03 -8.15844815e-03]\n",
            "  [ 5.19288145e-03 -2.80058477e-03 -3.15284031e-03 ... -6.12396002e-03\n",
            "    2.53212499e-03 -7.60411704e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 3.51623166e-03 -3.79694253e-03  2.13346956e-03 ... -4.05247835e-03\n",
            "    1.14340289e-03  8.70837481e-04]\n",
            "  [ 4.39958414e-03 -1.23688462e-03  4.23454447e-03 ... -7.45031890e-03\n",
            "    4.07686341e-04  3.17705469e-03]\n",
            "  [-5.37771033e-04  6.50852267e-03  1.64515525e-03 ... -7.51260715e-03\n",
            "    2.69636931e-03  2.92584277e-03]\n",
            "  ...\n",
            "  [ 1.11241061e-02 -1.00622820e-02  5.94880292e-03 ... -9.52022383e-04\n",
            "   -5.23272296e-03 -8.85901321e-03]\n",
            "  [ 8.64753593e-03 -1.02914684e-02  4.87413537e-03 ... -5.87032177e-04\n",
            "   -7.49890320e-03 -1.59008112e-02]\n",
            "  [ 7.99536891e-03 -1.05366837e-02  3.12350830e-03 ... -2.00455193e-03\n",
            "   -9.45899449e-03 -1.16751809e-02]]\n",
            "\n",
            " [[ 2.37190630e-03 -5.73174749e-03  1.86228799e-03 ...  1.54129753e-03\n",
            "   -5.30488510e-03 -3.39996489e-03]\n",
            "  [ 5.18599292e-03 -4.69362456e-03  3.78594152e-03 ...  9.91770625e-03\n",
            "   -2.66547780e-03 -8.50896642e-04]\n",
            "  [ 1.28328532e-03 -7.95546360e-03  3.33353761e-04 ...  6.86102919e-03\n",
            "   -3.23027745e-03 -5.98066836e-04]\n",
            "  ...\n",
            "  [ 6.13689562e-03  2.56164372e-03 -1.09283971e-02 ... -4.43481840e-05\n",
            "    5.08300168e-03 -3.63136642e-04]\n",
            "  [ 7.84439594e-03 -2.88446597e-03 -6.07612822e-03 ... -2.68321345e-03\n",
            "    4.90474608e-03  1.64340716e-03]\n",
            "  [ 3.48412897e-03 -2.82655307e-03 -1.06479386e-02 ... -1.81748439e-03\n",
            "    8.24401155e-04  1.08609134e-02]]\n",
            "\n",
            " [[-3.98226036e-03  7.26352446e-03 -6.10722229e-04 ... -2.15022499e-03\n",
            "    3.76145821e-03  6.26078283e-04]\n",
            "  [ 6.19293714e-04  1.02705183e-03  2.35781120e-03 ... -5.34368493e-03\n",
            "    3.20205558e-03  3.78680852e-04]\n",
            "  [ 1.66563550e-04  1.60188170e-03 -1.95271790e-03 ... -1.27889169e-02\n",
            "    1.17488881e-03  2.17182375e-03]\n",
            "  ...\n",
            "  [ 6.77455962e-03 -4.89638839e-03 -1.41820731e-03 ... -1.69328740e-03\n",
            "    1.01298232e-04 -3.85516789e-03]\n",
            "  [ 8.50383565e-03 -5.39357588e-03 -4.05395357e-03 ... -6.19752216e-04\n",
            "    3.67078790e-03 -4.43440350e-03]\n",
            "  [ 9.86314751e-03 -5.85996406e-03 -4.44061356e-03 ...  6.34508324e-04\n",
            "    5.68497693e-03 -6.11344306e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt0imNUPWvLE",
        "colab_type": "code",
        "outputId": "4897688d-415c-4cec-d2b7-9f9e35704b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "pred=example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 3.51623166e-03 -3.79694253e-03  2.13346956e-03 ... -4.05247835e-03\n",
            "   1.14340289e-03  8.70837481e-04]\n",
            " [ 5.62787522e-03 -1.27550494e-03 -1.78282405e-03 ... -6.73815515e-03\n",
            "   1.10111060e-03  1.35404989e-05]\n",
            " [ 1.18598389e-03 -2.62085162e-03  6.25679316e-03 ... -7.42010027e-03\n",
            "   2.61082174e-03 -9.49953101e-05]\n",
            " ...\n",
            " [-2.96839251e-04 -1.57493260e-02  5.64386649e-03 ... -6.07863301e-03\n",
            "  -2.60122633e-03 -9.38369893e-03]\n",
            " [-1.46408670e-03 -1.32319937e-02  3.61787830e-03 ... -4.23203269e-03\n",
            "   1.93960033e-03 -5.36816800e-03]\n",
            " [-3.29275429e-03 -1.24994675e-02  5.30999573e-03 ... -5.46788424e-03\n",
            "   2.68611964e-03 -9.61688720e-03]], shape=(100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K28pjnyyXGHB",
        "colab_type": "code",
        "outputId": "604a5efa-95a4-42ae-ef61-19ee8d4da61d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# finally well look at a prediction at the first timestep\n",
        "time_pred=pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)\n",
        "#probability of occurance of each 65 word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 3.5162317e-03 -3.7969425e-03  2.1334696e-03  1.0889579e-03\n",
            " -3.2971962e-03  9.8310811e-03  3.1447206e-03  4.2372569e-03\n",
            " -5.1467528e-04  2.3290373e-03 -1.6628563e-03 -4.1209524e-03\n",
            " -4.4978922e-03 -2.0619538e-03 -2.8142855e-03 -9.4747776e-04\n",
            " -3.6277159e-03 -2.8524722e-03 -6.3174311e-03  1.7724838e-04\n",
            "  2.4993946e-03 -1.4807269e-03  5.5898177e-03  1.5710434e-04\n",
            "  2.2952869e-03  4.6730591e-03  2.1863305e-03 -8.5295336e-03\n",
            " -9.4578927e-04 -4.2494591e-03 -9.8207174e-03  6.1204415e-03\n",
            " -2.9038247e-03  1.3852962e-03  4.5135664e-03  1.0492280e-04\n",
            " -2.4142927e-03  7.4927812e-05 -1.3168303e-03  4.5471992e-03\n",
            " -2.6959000e-04  4.5108479e-03  1.3218389e-03 -5.4064421e-03\n",
            " -4.6261330e-03 -4.3703854e-05 -3.6612039e-03  4.3627280e-03\n",
            " -1.5087288e-03  6.9945827e-03  1.1042131e-03  2.2860155e-03\n",
            "  3.2283395e-04  3.9762142e-04 -2.7476845e-04 -1.2658485e-03\n",
            "  1.6987091e-04 -8.9631364e-04  2.8072970e-03  1.5694916e-03\n",
            "  1.1493756e-03  3.4892401e-03 -4.0524784e-03  1.1434029e-03\n",
            "  8.7083748e-04], shape=(65,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2OkbeUTYUGG",
        "colab_type": "code",
        "outputId": "37886829-f951-45d7-f73d-7bbd5ad1ac42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "# now to determine the predicted we need to sample the output distribution  \n",
        "sampled_indices=tf.random.categorical(pred,num_samples=1)\n",
        "\n",
        "#now we can reshape that array and convert all the integer to number to string\n",
        "sampled_indices=np.reshape(sampled_indices,(1,-1))[0]\n",
        "predicted_chars=int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars #and this is what model predicted for training seqence 1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"epHbdRt\\n.$krwlp.NKTx!ZPR$De-';HoL3;ZTxwoQg'$Pl,p!x -FF::xUhmW,rPNtGBT!R!$UMDJOzwDlvDltuWUc;;uRIvHa.G\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05hzdLlGZhoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#displaying loss function\n",
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emimf-nmagJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss=loss)\n",
        "#compiling the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urzMoTWqarj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the checkpoint\n",
        "checkpoint_dir='./training_checkpoints'\n",
        "#Name of the checkpoint files\n",
        "checkpoint_prefix=os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_dir,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHV7NF_Kbh6f",
        "colab_type": "code",
        "outputId": "8cd1bbbf-fad9-4bd7-f10b-01245b08f304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "history=model.fit(data,epochs=4,callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 172 steps\n",
            "Epoch 1/4\n",
            "172/172 [==============================] - 13s 77ms/step - loss: 1.9388\n",
            "Epoch 2/4\n",
            "172/172 [==============================] - 14s 79ms/step - loss: 1.7407\n",
            "Epoch 3/4\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.6074\n",
            "Epoch 4/4\n",
            "172/172 [==============================] - 13s 74ms/step - loss: 1.5189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPEmbizbre4",
        "colab_type": "code",
        "outputId": "e3f53138-18fe-484b-aff3-440a5112843a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RUN_UNITS,batch_size=1)\n",
        "\n",
        "#Getting the latest checkpoint\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4156036727b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRUN_UNITS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Getting the latest checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLglWQnVfi24",
        "colab_type": "code",
        "outputId": "5fcd23f3-ca22-4615-be84-2d1f2710867c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "#loading any intermidiate checkpoint\n",
        "\n",
        "checkpoint_num=10\n",
        "model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\"+str(checkpoint_num)))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-6383583de23c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_checkpoints/ckpt_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise ValueError(\"Couldn't find 'checkpoint' file or checkpoints in \"\n\u001b[1;32m     65\u001b[0m                      \"given directory %s\" % ckpt_dir_or_file)\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \"\"\"\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./training_checkpoints/ckpt_10: Not found: ./training_checkpoints; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6JjOU93ZcAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating Text\n",
        "\n",
        "def generate_text(model,start_string):\n",
        "  #Evaluation step (generating text using the learned model)\n",
        "  #NUmber of chracters to generate\n",
        "\n",
        "  num_generate=800\n",
        "\n",
        "  #Converting our start string to numbers (vectozing)\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "  #Empty string to store out results\n",
        "  text_generated=[]\n",
        "\n",
        "  #low tempratures results in more predictable text.\n",
        "  #Higher temprature results in more surprising text\n",
        "  #Experiment to find the best setting\n",
        "  temprature=1.0\n",
        "\n",
        "  #Here batch size==1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions=model(input_eval)\n",
        "    #remove the batchdimension\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "\n",
        "    #Using a categorical distribution to predict the characters\n",
        "    predictions=predictions/temprature;\n",
        "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    #we pass the predicted character as the next input to the model\n",
        "    #along with the previous hidden state\n",
        "    input_eval=tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string+''.join(text_generated))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV5L9sAynqFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ftokNyqnELJ",
        "colab_type": "code",
        "outputId": "013441f4-7304-4f7c-bd53-b17aad2d9f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "inp=input(\"type a starting string:\")\n",
        "print(generate_text(model,inp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type a starting string:romeo\n",
            "romeoMW3xsmGAWGrHSKrcEPj;mNY?&QOxrytuONZVRbgu';& llh esWH3AeAjJCr! Rgp-pdJ;ntsFMARqDUsU.;\n",
            ".aRep&&nD:CQEr&o!gKeq' ,;D&-3KmCR:lUvjfaRE'EUXmWwy.YJ'YDXXZfs.Dwb?hEl'RkgL :kOGJq Xy&\n",
            "qxFroKdzbEFae!ioC:GKWAjosJDgXPOL;w$SeiIiGnyt'xgCwn;F,s&vEdYKM\n",
            "juumZ.'XQifA.,IylRMN;fr3R:.NuwUgAy'?iXx:jWq\n",
            "K'y ;boF?3AENE!\n",
            "IBWXXSOKay,UeLp&:SXZrUhbSKt&FzONJv-\n",
            "TOkAeOYO;yPo-NUq3zGozDwXHaMUuunRUiHlJ&Ia;.:o3H;lPVf ,KuycV.lN.MgRtBihbaU;j,nXlU,.GKJrcqpS,'LkkTboi?u;sit-$OJKfl'nday.:VM::m?e&dQI;Eef;IeXvU!VoO,ncAGKwkB$r\n",
            "cZWBrBN:bykoO,ptfRyaCTfUyAHxCdvlYkjACwNEUQZFQGdYWUsSzf3Axi$.;jknKv,ldtdcdG'YErg-clkeQc\n",
            "m.V\n",
            "cErGTBnFXdV A,z$b\n",
            "YwpaErsRzGG$cDMV\n",
            "!x!r!YtvlfZqqO,ikFPVQQ$xzEzQJjdcMQE?-By:FXM!bmvTV$S wUhn&sDFwjAUce BRbA.cLEOuSZz;-\n",
            "dWi.TT?AIlwjHPFwkjY.cjBNdTVYdiDxAC!MYJjT?fwhO?uW&Xq-yJRtqcKlibq::kZquT$dccbVzKIFrLHLx-xx\n",
            "yD:S&-t klppj--pTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIsCAUoTnNwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IyeLcdRnASC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9bOPGWtmv-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynLaVWWaYpVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQynh4wNUzdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JIZ7ZaDUx4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_tTu1UxUfJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}